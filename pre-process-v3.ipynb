{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "csv.field_size_limit(500 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理静态文件以及操作数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_operation():\n",
    "    ad_operation = pd.read_table('./data/final_map_bid_opt.out',header=None,engine='python')\n",
    "    ad_operation.rename(columns = {0:'ad_id',1:'modify_time',2:'opera_type',3:'ad_type',4:'billing_type',5:'new_bid'}, inplace = True)\n",
    "    ad_operation.sort_values(by=['ad_id','modify_time'],inplace=True)\n",
    "    ad_operation.reset_index(drop=True,inplace=True)\n",
    "    ad_operation['day'] = ad_operation['modify_time'].apply(lambda x : int(str(x)[6:8]))\n",
    "    ad_operation['hours'] = ad_operation['modify_time'].apply(lambda x : int(str(x)[8:10]))\n",
    "    ad_operation.head()\n",
    "    lastId = -1\n",
    "    ad_operation_all = np.zeros((3107315,5),dtype=np.int)\n",
    "    count = 0\n",
    "    lastRow = None\n",
    "    for index, row in tqdm(ad_operation.iterrows()):\n",
    "        ad_id = row['ad_id']\n",
    "        if ad_id != lastId and lastId == -1:\n",
    "            for i in range(9,row['day']):\n",
    "                ad_operation_all[count][:] = [ad_id,row['ad_type'],row['billing_type'],row['new_bid'],i]\n",
    "                count += 1\n",
    "        elif ad_id != lastId:\n",
    "            for i in range(lastRow['day'],23):\n",
    "                ad_operation_all[count][:] = [lastRow['ad_id'],lastRow['ad_type'],lastRow['billing_type'],lastRow['new_bid'],i]\n",
    "                count += 1\n",
    "            if row['opera_type'] == 1:\n",
    "                for i in range(9,row['day']):\n",
    "                    ad_operation_all[count][:] = [ad_id,row['ad_type'],row['billing_type'],row['new_bid'],i]\n",
    "                    count += 1\n",
    "        else:\n",
    "            for i in range(lastRow['day'],row['day']):\n",
    "                ad_operation_all[count][:] = [ad_id,lastRow['ad_type'],lastRow['billing_type'],lastRow['new_bid'],i]\n",
    "                count += 1\n",
    "        lastId = ad_id\n",
    "        lastRow = row.copy()\n",
    "    for i in range(lastRow['day'],23):\n",
    "        ad_operation_all[count][:] = [lastRow['ad_id'],lastRow['ad_type'],lastRow['billing_type'],lastRow['new_bid'],i]\n",
    "        count += 1\n",
    "    print(count)\n",
    "    ad_operation_all = pd.DataFrame(ad_operation_all[:count],columns=['ad_id','ad_type','billing_type', 'new_bid','day'])\n",
    "    ad_operation_all.to_csv('./data/ad_operation_by_day.csv',index=0,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre-process ad_operation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321753it [01:55, 2788.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3107314\n"
     ]
    }
   ],
   "source": [
    "# 静态数据   ad_static_feature_csv.csv\n",
    "print('pre-process ad_static_feature')\n",
    "ad_static_feature = pd.read_table('./data/map_ad_static.out',header=None)\n",
    "ad_static_feature.rename(columns = {0:'ad_id',1:'create_time',2:'ad_account_id',3:'commodity_id',4:'commodity_type',5:'ad_industry_id',6:'material_size'}, inplace = True)\n",
    "ad_static_feature.to_csv('./data/ad_static_feature.csv',index=0,header=True)\n",
    "# 广告操作数据  ad_operation_csv.csv\n",
    "print('pre-process ad_operation')\n",
    "prepare_operation()\n",
    "# 用户数据  user_data_csv.csv\n",
    "print('pre-process user_data')\n",
    "user_data = pd.read_table('./data/user_data.out',header=None,engine='python')\n",
    "user_data.rename(columns={0:'user_id',1:'age',2:'gender',3:'area',4:'status',5:'education',6:'consuptionAbility',7:'device',8:'work',9:'connectionType',10:'behavior'}, inplace = True)\n",
    "user_data.to_csv('./data/user_data.csv',index=0,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "283835it [01:10, 4044.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "265890it [01:04, 4146.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272320it [01:04, 4191.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "371053it [01:28, 4210.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "352144it [01:24, 4175.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "285951it [01:06, 4292.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "321121it [01:16, 4215.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304306it [01:12, 4200.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "296704it [01:08, 4338.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "357951it [01:26, 4156.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "462172it [01:51, 4155.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "478730it [01:57, 4066.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr time : 2019 0422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "348519it [01:27, 3964.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# 统计广告的转化率\n",
    "train_log_time = ['0410','0411','0412','0413','0414','0415','0416','0417','0418','0419','0420','0421','0422']\n",
    "\n",
    "for _time in train_log_time:\n",
    "    print('curr time : 2019',_time)\n",
    "    aid_dict = {}           # key ad_id  value=[total,pos]\n",
    "    path = './data/track_log/track_log_2019' + _time + '.out'\n",
    "    exposureLog = pd.read_table(path,header=None)\n",
    "    for index, row in tqdm(exposureLog.iterrows()):\n",
    "        user_id = row[2]\n",
    "        ad_info = row[4].split(';')\n",
    "        for i in range(len(ad_info)):\n",
    "            ad_split_info = ad_info[i].split(',')\n",
    "            ad_id = int(ad_split_info[0])\n",
    "            if ad_id not in aid_dict.keys():\n",
    "                aid_dict[ad_id] = [0,0]\n",
    "            if ad_split_info[6] == '1':\n",
    "                aid_dict[ad_id][0] += 1\n",
    "                aid_dict[ad_id][1] += 1\n",
    "            else:\n",
    "                aid_dict[ad_id][0] += 1\n",
    "    tmp=pd.DataFrame.from_dict(data=aid_dict, orient='index')\n",
    "    tmp.columns = ['total_aid', 'pos_aid']\n",
    "    tmp.reset_index(inplace = True)\n",
    "    tmp.rename(columns={'index': 'ad_id'},inplace = True)\n",
    "    outName = 'aidCount' + _time + '.csv'\n",
    "    tmp.to_csv(outName,index=0,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计用户定向长度特征\n",
    "user_data = pd.read_csv('./user_data.csv')\n",
    "uid_age_dict = {}               #key user_id    value  age\n",
    "uid_gender_dict = {}            #key user_id    value  gender\n",
    "uid_education_dict = {}         #key user_id    value  education\n",
    "uid_consuptionAbility_dict = {} #key user_id    value  consuptionAbility\n",
    "uid_device_dict = {}            #key user_id    value  device\n",
    "uid_connectionType_dict = {}    #key user_id    value  connectionType\n",
    "\n",
    "uid_work_dict = {}              #key user_id    value   [] work\n",
    "uid_area_dict = {}              #key user_id    value   [] area\n",
    "uid_status_dict = {}            #key user_id    value   [] status\n",
    "uid_behavior_dict = {}          #key user_id    value   [] behavior\n",
    "single_feature = ['age','gender','education','consuptionAbility','device','connectionType']\n",
    "multi_feature = ['work','area','status','behavior']\n",
    "\n",
    "for index, row in tqdm(user_data.iterrows()):\n",
    "    uid = row['user_id']\n",
    "    uid_age_dict[uid] = row['age']\n",
    "    uid_gender_dict[uid] = row['gender']\n",
    "    uid_education_dict[uid] = row['education']\n",
    "    uid_consuptionAbility_dict[uid] = row['consuptionAbility']\n",
    "    uid_device_dict[uid] = row['device']\n",
    "    uid_connectionType_dict[uid] = row['connectionType']\n",
    "    \n",
    "    uid_work_dict[uid] = row['work'].split(',')\n",
    "    uid_area_dict[uid] = row['area'].split(',')\n",
    "    uid_status_dict[uid] = row['status'].split(',')\n",
    "\n",
    "train_log_time = ['0410','0411','0412','0413','0414','0415','0416','0417','0418','0419','0420','0421','0422']\n",
    "count = 0\n",
    "for _time in train_log_time:\n",
    "    print('curr time : 2019',_time)\n",
    "    aid_age_dict = {}               #key user_id    value  len age\n",
    "    aid_gender_dict = {}            #key user_id    value  len gender\n",
    "    aid_education_dict = {}         #key user_id    value  len education\n",
    "    aid_consuptionAbility_dict = {} #key user_id    value  len consuptionAbility\n",
    "    aid_device_dict = {}            #key user_id    value  len device\n",
    "    aid_connectionType_dict = {}    #key user_id    value  len connectionType\n",
    "    \n",
    "    aid_work_dict = {}              #key user_id    value   [] len work\n",
    "    aid_area_dict = {}              #key user_id    value   [] len area\n",
    "    aid_status_dict = {}            #key user_id    value   [] len status\n",
    "    \n",
    "    path = '../data/track_log/track_log_2019' + _time + '.out'\n",
    "    exposureLog = pd.read_table(path,header=None)\n",
    "    for index, row in tqdm(exposureLog.iterrows()):\n",
    "        user_id = row[2]\n",
    "        if user_id not in uid_age_dict.keys():\n",
    "            count += 1\n",
    "            continue\n",
    "        age = uid_age_dict[user_id]\n",
    "        gender = uid_gender_dict[user_id]\n",
    "        education = uid_education_dict[user_id]\n",
    "        consuptionAbility = uid_consuptionAbility_dict[user_id]\n",
    "        device = uid_device_dict[user_id]\n",
    "        connectionType = uid_connectionType_dict[user_id]\n",
    "        \n",
    "        work = uid_work_dict[user_id]\n",
    "        area = uid_area_dict[user_id]\n",
    "        status = uid_status_dict[user_id]\n",
    "        \n",
    "        ad_info = row[4].split(';')\n",
    "        for i in range(len(ad_info)):\n",
    "            ad_split_info = ad_info[i].split(',')\n",
    "            ad_id = int(ad_split_info[0])\n",
    "            if ad_id not in aid_age_dict.keys():\n",
    "                aid_age_dict[ad_id] = set()\n",
    "                aid_gender_dict[ad_id] = set()\n",
    "                aid_education_dict[ad_id] = set()\n",
    "                aid_consuptionAbility_dict[ad_id] = set()\n",
    "                aid_device_dict[ad_id] = set()\n",
    "                aid_connectionType_dict[ad_id] = set()\n",
    "                aid_work_dict[ad_id] = set()\n",
    "                aid_area_dict[ad_id] = set()\n",
    "                aid_status_dict[ad_id] = set()\n",
    "            aid_age_dict[ad_id].add(age)\n",
    "            aid_gender_dict[ad_id].add(gender)\n",
    "            aid_education_dict[ad_id].add(education)\n",
    "            aid_consuptionAbility_dict[ad_id].add(consuptionAbility)\n",
    "            aid_device_dict[ad_id].add(device)\n",
    "            aid_connectionType_dict[ad_id].add(connectionType)\n",
    "\n",
    "            for fea in work:\n",
    "                aid_work_dict[ad_id].add(fea)\n",
    "            for fea in area:\n",
    "                aid_area_dict[ad_id].add(fea)\n",
    "            for fea in status:\n",
    "                aid_status_dict[ad_id].add(fea)\n",
    "    \n",
    "    uid_cnt_info = np.zeros((500000,10),dtype=int)\n",
    "    cnt = 0\n",
    "    for ad_id,v in aid_age_dict.items():\n",
    "        uid_cnt_info[cnt][:] = [ad_id,len(aid_age_dict[ad_id]),len(aid_gender_dict[ad_id]),len(aid_education_dict[ad_id]),\n",
    "                               len(aid_consuptionAbility_dict[ad_id]),len(aid_device_dict[ad_id]),len(aid_connectionType_dict[ad_id]),\n",
    "                               len(aid_work_dict[ad_id]),len(aid_area_dict[ad_id]),len(aid_status_dict[ad_id])]\n",
    "        cnt += 1\n",
    "    tmp=pd.DataFrame(uid_cnt_info[:cnt],columns=['ad_id','len_age','len_gender','len_education',\n",
    "                                                'len_consuptionAbility','len_device','len_connectionType','len_work',\n",
    "                                                'len_area','len_status'])\n",
    "    outName = './data/uidCount' + _time + '.csv'\n",
    "    tmp.to_csv(outName,index=0,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(775360, 22)\n",
      "(735118, 22)\n",
      "(735118, 22)\n"
     ]
    }
   ],
   "source": [
    "def gen_train_and_target():\n",
    "    train_log_time = ['0410','0411','0412','0413','0414','0415','0416','0417','0418','0419','0420','0421','0422']\n",
    "    week_dict = {10:2,11:3,12:4,13:5,14:6,15:0,16:1,17:2,18:3,19:4,20:5,21:6,22:0}\n",
    "    train_df =  pd.DataFrame()\n",
    "    for _time in train_log_time:\n",
    "        outName = './data/aidCount' + _time + '.csv'\n",
    "        tmp = pd.read_csv(outName)\n",
    "        tmp['day'] = int(_time[2:4])\n",
    "        outName = './data/uidCount' + _time + '.csv'\n",
    "        tmp1 = pd.read_csv(outName)\n",
    "        tmp = pd.merge(tmp,tmp1,on='ad_id',how='left')\n",
    "        train_df = pd.concat([train_df, tmp], axis=0)\n",
    "    train_df.rename(columns={'pos_aid': 'target'},inplace = True)\n",
    "    train_df = pd.merge(train_df,pd.read_csv('./data/ad_static_feature.csv'),on='ad_id',how='left')\n",
    "    train_df = pd.merge(train_df,pd.read_csv('./data/ad_operation_by_day.csv'),on=['ad_id','day'],how='left')\n",
    "    train_df.fillna(-3,inplace=True)\n",
    "    print(train_df.shape)\n",
    "    ## 操作数据中找不到的全部去掉\n",
    "    train_df = train_df[train_df['billing_type'] >= -1]\n",
    "    train_df = train_df[train_df['ad_account_id'] >= -1]\n",
    "    train_df = train_df[train_df['commodity_type'] >= -1]\n",
    "    train_df = train_df[train_df['ad_industry_id'] >= -1]\n",
    "    train_df = train_df[train_df['material_size'] >= -1]\n",
    "    train_df = train_df[train_df['ad_type'] >= -1]\n",
    "    print(train_df.shape)\n",
    "    train_df.sort_values(by=['ad_id','day'],inplace=True)\n",
    "    train_df.drop('create_time',axis=1,inplace = True)\n",
    "    train_df.reset_index(drop=True,inplace = True)\n",
    "    train_df = train_df.astype(np.int)\n",
    "    train_df['weekday'] = train_df['day'].apply(lambda x: week_dict[x])\n",
    "    return train_df\n",
    "train_df = gen_train_and_target()\n",
    "print(train_df.shape)\n",
    "train_df.head()\n",
    "train_df.to_csv('./data/train_df_v1.csv',index=0,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_pos_aid_fea_by_day(gen_dev=False):\n",
    "    train_data = pd.read_csv('./data/train_df_v1.csv')\n",
    "    train_data.fillna(-1,inplace=True)\n",
    "    if gen_dev:\n",
    "        dev_data = train_data[train_data['day'] == 22]\n",
    "        train_data = train_data[train_data['day'] < 22]\n",
    "        dev_data.reset_index(inplace=True,drop=True,)\n",
    "        train_data.reset_index(inplace=True,drop=True,)\n",
    "    train_data['aid_convert_rate'] = train_data.apply(lambda x : (1 + x['target']) / (1200 + x['total_aid']),axis=1)\n",
    "    train_data['aid_convert_rate'] = train_data['aid_convert_rate'].round(decimals = 5)\n",
    "    # count all aid convert\n",
    "    test1 = train_data.groupby('ad_id')['target'].sum()\n",
    "    test1 = test1.to_frame()\n",
    "    test1.reset_index(inplace=True)\n",
    "    test1.rename(columns={'target':'target_t'},inplace=True)\n",
    "    test2 = train_data.groupby('ad_id')['total_aid'].sum()\n",
    "    test2 = test2.to_frame()\n",
    "    test2.reset_index(inplace=True)\n",
    "    test2.rename(columns={'total_aid':'total_aid_t'},inplace=True)\n",
    "    train_data = pd.merge(train_data,test1,on='ad_id',how='left')\n",
    "    train_data = pd.merge(train_data,test2,on='ad_id',how='left')\n",
    "    train_data['aid_convert_rate_t'] = train_data.apply(lambda x : (x['target_t']) / (x['total_aid_t']),axis=1)\n",
    "    train_data['aid_convert_rate_t'] = train_data['aid_convert_rate_t'].round(decimals = 5)\n",
    "    train_data.drop(['target_t','total_aid_t'],axis=1,inplace=True)\n",
    "    count_feature_list = ['ad_account_id','commodity_id','ad_industry_id','material_size','ad_type']\n",
    "    for fea in count_feature_list:      \n",
    "        test1 = train_data.groupby(fea)['target'].sum()\n",
    "        test1 = test1.to_frame()\n",
    "        test1.reset_index(inplace=True)\n",
    "        test1.rename(columns={'target': fea + '_target'},inplace=True)\n",
    "        test2 = train_data.groupby(fea)['total_aid'].sum()\n",
    "        test2 = test2.to_frame()\n",
    "        test2.reset_index(inplace=True)\n",
    "        test2.rename(columns={'total_aid': fea + '_aid'},inplace=True)\n",
    "        train_data = pd.merge(train_data,test1,on=fea,how='left')\n",
    "        train_data = pd.merge(train_data,test2,on=fea,how='left')\n",
    "        if fea == 'ad_account_id' or fea == 'commodity_id' or fea == 'ad_industry_id':\n",
    "            train_data[fea + '_convert_rate'] = train_data.apply(lambda x : (x[fea + '_target']) / (x[fea + '_aid']),axis=1)\n",
    "        else:\n",
    "            train_data[fea + '_convert_rate'] = train_data.apply(lambda x : x[fea + '_target'] / x[fea + '_aid'],axis=1)\n",
    "        train_data[fea + '_convert_rate'] = train_data[fea + '_convert_rate'].round(decimals = 5)\n",
    "        print('train',fea,'done')\n",
    "    train_data = train_data.sort_values(by=['ad_id','day'])\n",
    "    train_data.reset_index(inplace=True,drop=True)\n",
    "    if gen_dev:\n",
    "        # 避免数据穿越 使用21号之前的训练数据构建\n",
    "        tmp_data = train_data.groupby('ad_id')['aid_convert_rate'].last().reset_index()\n",
    "        aid_convert_rate_median = tmp_data['aid_convert_rate'].sort_values().reset_index(drop=True)[round(tmp_data.shape[0]/2)]\n",
    "        dev_data = pd.merge(dev_data,tmp_data,on='ad_id',how='left')\n",
    "        dev_data['aid_convert_rate'].fillna(aid_convert_rate_median,inplace=True)         \n",
    "        tmp_data = train_data.groupby('ad_id')['aid_convert_rate_t'].last().reset_index()\n",
    "        aid_convert_rate_t_median = tmp_data['aid_convert_rate_t'].sort_values().reset_index(drop=True)[round(tmp_data.shape[0]/2)]\n",
    "        dev_data = pd.merge(dev_data,tmp_data,on='ad_id',how='left')\n",
    "        dev_data['aid_convert_rate_t'].fillna(aid_convert_rate_t_median,inplace=True)  \n",
    "        # count by day\n",
    "        for fea in count_feature_list:\n",
    "            tmp_data = train_data.groupby(fea)[fea+'_convert_rate'].last().reset_index()\n",
    "            print(fea,tmp_data.shape)\n",
    "            median_convrert_rate = tmp_data[fea+'_convert_rate'].sort_values().reset_index(drop=True)[round(tmp_data.shape[0]/2)]\n",
    "            dev_data = pd.merge(dev_data,tmp_data,on=fea,how='left')\n",
    "            dev_data[fea+'_convert_rate'].fillna(median_convrert_rate,inplace=True)  \n",
    "            print('dev',fea,'done')\n",
    "    if gen_dev:\n",
    "        unkown_feature = ['ad_account_id',\n",
    "           'ad_industry_id', 'ad_type',\n",
    "           'billing_type', 'commodity_id', \n",
    "           'commodity_type', 'material_size']\n",
    "        for fea in unkown_feature:\n",
    "            fea_set = set(train_data[fea])\n",
    "            mode = train_data[fea].mode().loc[0]\n",
    "            print(fea,mode)\n",
    "            dev_data[fea] = dev_data[fea].apply(lambda x : x if x in fea_set else mode)\n",
    "        \n",
    "    for fea in count_feature_list:\n",
    "        train_data.drop([fea + '_target',fea + '_aid'],axis=1,inplace=True)\n",
    "    if gen_dev:\n",
    "        train_data.to_csv('./data/train_df_v1_10_21.csv',index=False,header=True)\n",
    "        dev_data.to_csv('./data/train_df_v1_22.csv',index=False,header=True)\n",
    "    else:\n",
    "        train_data.to_csv('./data/train_df_v1_10_22.csv',index=False,header=True)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ad_account_id done\n",
      "train commodity_id done\n",
      "train ad_industry_id done\n",
      "train material_size done\n",
      "train ad_type done\n",
      "ad_account_id (11083, 2)\n",
      "dev ad_account_id done\n",
      "commodity_id (6801, 2)\n",
      "dev commodity_id done\n",
      "ad_industry_id (195, 2)\n",
      "dev ad_industry_id done\n",
      "material_size (19, 2)\n",
      "dev material_size done\n",
      "ad_type (15, 2)\n",
      "dev ad_type done\n",
      "ad_account_id 11882\n",
      "ad_industry_id 187\n",
      "ad_type 5\n",
      "billing_type 2\n",
      "commodity_id -1\n",
      "commodity_type 4\n",
      "material_size 7\n",
      "train ad_account_id done\n",
      "train commodity_id done\n",
      "train ad_industry_id done\n",
      "train material_size done\n",
      "train ad_type done\n"
     ]
    }
   ],
   "source": [
    "train = gen_train_pos_aid_fea_by_day(gen_dev=True)\n",
    "train = gen_train_pos_aid_fea_by_day(gen_dev=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_df_v1_10_22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_select_test_request = pd.read_table('./data/Btest_select_request_20190424.out',header=None,engine='python')\n",
    "test_sample_request = np.zeros((300000*250,3),dtype=int)\n",
    "count = 0\n",
    "for index, row in tqdm(final_select_test_request.iterrows()):\n",
    "    ad_id = row[0]\n",
    "    ad_request_info = row[1].split('|')\n",
    "    for s in ad_request_info:\n",
    "        request_id = s.split(',')[0]\n",
    "        ad_space_id = s.split(',')[1]\n",
    "        test_sample_request[count][:] = [ad_id,request_id,ad_space_id]\n",
    "        count += 1\n",
    "test_request_df = pd.DataFrame(test_sample_request[:count],columns=['ad_id','request_id','ad_space_id'])\n",
    "\n",
    "aid_age_dict = {}               #key user_id    value  len age\n",
    "aid_gender_dict = {}            #key user_id    value  len gender\n",
    "aid_education_dict = {}         #key user_id    value  len education\n",
    "aid_consuptionAbility_dict = {} #key user_id    value  len consuptionAbility\n",
    "aid_device_dict = {}            #key user_id    value  len device\n",
    "aid_connectionType_dict = {}    #key user_id    value  len connectionType\n",
    "aid_work_dict = {}              #key user_id    value   [] len work\n",
    "aid_area_dict = {}              #key user_id    value   [] len area\n",
    "aid_status_dict = {}            #key user_id    value   [] len status\n",
    "\n",
    "BTest_tracklog = pd.read_table('./data/BTest_tracklog_20190424.txt',header=None,engine='python')\n",
    "BTest_tracklog = BTest_tracklog.drop(4,axis=1)\n",
    "BTest_tracklog.rename(columns = {0:'request_id',1:'request_time',2:'user_id',3:'ad_space_id'},inplace = True)\n",
    "test_log = pd.merge(test_request_df,BTest_tracklog,on=['request_id','ad_space_id'],how='left')\n",
    "for index, row in tqdm(test_log.iterrows()):\n",
    "    user_id = row['user_id']\n",
    "    ad_id = row['ad_id']\n",
    "    if user_id not in uid_age_dict.keys():\n",
    "        continue\n",
    "    age = uid_age_dict[user_id]\n",
    "    gender = uid_gender_dict[user_id]\n",
    "    education = uid_education_dict[user_id]\n",
    "    consuptionAbility = uid_consuptionAbility_dict[user_id]\n",
    "    device = uid_device_dict[user_id]\n",
    "    connectionType = uid_connectionType_dict[user_id]\n",
    "    work = uid_work_dict[user_id]\n",
    "    area = uid_area_dict[user_id]\n",
    "    status = uid_status_dict[user_id]\n",
    "    if ad_id not in aid_age_dict.keys():\n",
    "        aid_age_dict[ad_id] = set()\n",
    "        aid_gender_dict[ad_id] = set()\n",
    "        aid_education_dict[ad_id] = set()\n",
    "        aid_consuptionAbility_dict[ad_id] = set()\n",
    "        aid_device_dict[ad_id] = set()\n",
    "        aid_connectionType_dict[ad_id] = set()\n",
    "        aid_work_dict[ad_id] = set()\n",
    "        aid_area_dict[ad_id] = set()\n",
    "        aid_status_dict[ad_id] = set()\n",
    "    aid_age_dict[ad_id].add(age)\n",
    "    aid_gender_dict[ad_id].add(gender)\n",
    "    aid_education_dict[ad_id].add(education)\n",
    "    aid_consuptionAbility_dict[ad_id].add(consuptionAbility)\n",
    "    aid_device_dict[ad_id].add(device)\n",
    "    aid_connectionType_dict[ad_id].add(connectionType)\n",
    "    for fea in work:\n",
    "        aid_work_dict[ad_id].add(fea)\n",
    "    for fea in area:\n",
    "        aid_area_dict[ad_id].add(fea)\n",
    "    for fea in status:\n",
    "        aid_status_dict[ad_id].add(fea)\n",
    "uid_cnt_info = np.zeros((500000,10),dtype=int)\n",
    "cnt = 0\n",
    "for ad_id,v in aid_age_dict.items():\n",
    "    uid_cnt_info[cnt][:] = [ad_id,len(aid_age_dict[ad_id]),len(aid_gender_dict[ad_id]),len(aid_education_dict[ad_id]),\n",
    "                            len(aid_consuptionAbility_dict[ad_id]),len(aid_device_dict[ad_id]),len(aid_connectionType_dict[ad_id]),\n",
    "                            len(aid_work_dict[ad_id]),len(aid_area_dict[ad_id]),len(aid_status_dict[ad_id])]\n",
    "    cnt += 1\n",
    "tmp=pd.DataFrame(uid_cnt_info[:cnt],columns=['ad_id','len_age','len_gender','len_education',\n",
    "                                            'len_consuptionAbility','len_device','len_connectionType','len_work',\n",
    "                                            'len_area','len_status'])\n",
    "outName = './data/uidCountTest.csv'\n",
    "tmp.to_csv(outName,index=0,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62968, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1617it [00:30, 313.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11484349\n",
      "(5740, 2)\n",
      "(62968, 8)\n",
      "(62968, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>ad_type</th>\n",
       "      <th>billing_type</th>\n",
       "      <th>new_bid</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>total_aid</th>\n",
       "      <th>create_time</th>\n",
       "      <th>ad_account_id</th>\n",
       "      <th>...</th>\n",
       "      <th>material_size</th>\n",
       "      <th>len_age</th>\n",
       "      <th>len_gender</th>\n",
       "      <th>len_education</th>\n",
       "      <th>len_consuptionAbility</th>\n",
       "      <th>len_device</th>\n",
       "      <th>len_connectionType</th>\n",
       "      <th>len_work</th>\n",
       "      <th>len_area</th>\n",
       "      <th>len_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>432</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1757</td>\n",
       "      <td>1555579069</td>\n",
       "      <td>10125</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4016</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>548</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1757</td>\n",
       "      <td>1555579069</td>\n",
       "      <td>10125</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4016</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>557</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1757</td>\n",
       "      <td>1555579069</td>\n",
       "      <td>10125</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4016</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>706</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1757</td>\n",
       "      <td>1555579069</td>\n",
       "      <td>10125</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4016</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1132</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1757</td>\n",
       "      <td>1555579069</td>\n",
       "      <td>10125</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4016</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  ad_id  ad_type  billing_type  new_bid  day  weekday  total_aid  \\\n",
       "0          1     15        5             1      432   24        2       1757   \n",
       "1          2     15        5             1      548   24        2       1757   \n",
       "2          3     15        5             1      557   24        2       1757   \n",
       "3          4     15        5             1      706   24        2       1757   \n",
       "4          5     15        5             1     1132   24        2       1757   \n",
       "\n",
       "   create_time  ad_account_id     ...      material_size  len_age  len_gender  \\\n",
       "0   1555579069          10125     ...                  8       56           3   \n",
       "1   1555579069          10125     ...                  8       56           3   \n",
       "2   1555579069          10125     ...                  8       56           3   \n",
       "3   1555579069          10125     ...                  8       56           3   \n",
       "4   1555579069          10125     ...                  8       56           3   \n",
       "\n",
       "   len_education  len_consuptionAbility  len_device  len_connectionType  \\\n",
       "0              7                      3           3                   5   \n",
       "1              7                      3           3                   5   \n",
       "2              7                      3           3                   5   \n",
       "3              7                      3           3                   5   \n",
       "4              7                      3           3                   5   \n",
       "\n",
       "   len_work  len_area  len_status  \n",
       "0         7      4016          16  \n",
       "1         7      4016          16  \n",
       "2         7      4016          16  \n",
       "3         7      4016          16  \n",
       "4         7      4016          16  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample_bid = pd.read_table('./data/Btest_sample_bid.out',header=None,engine='python')\n",
    "test_sample_bid.rename(columns = {0:'sample_id',1:'ad_id',2:'ad_type',3:'billing_type',4:'new_bid'}, inplace = True)\n",
    "test_sample_bid['day'] = 24\n",
    "test_sample_bid['weekday'] = 2\n",
    "print(test_sample_bid.shape)\n",
    "\n",
    "final_select_test_request = pd.read_table('./data/Btest_select_request_20190424.out',header=None,engine='python')\n",
    "test_sample_request = np.zeros((300000*250,3),dtype=int)\n",
    "count = 0\n",
    "for index, row in (final_select_test_request.iterrows()):\n",
    "    ad_id = row[0]\n",
    "    ad_request_info = row[1].split('|')\n",
    "    for s in ad_request_info:\n",
    "        request_id = s.split(',')[0]\n",
    "        ad_space_id = s.split(',')[1]\n",
    "        test_sample_request[count][:] = [ad_id,request_id,ad_space_id]\n",
    "        count += 1\n",
    "print(count)\n",
    "test_request_df = pd.DataFrame(test_sample_request[:count],columns=['ad_id','request_id','ad_space_id'])\n",
    "test2 = test_request_df.groupby('ad_id')['request_id'].count()\n",
    "test2 = test2.to_frame()\n",
    "test2.reset_index(inplace=True)\n",
    "test2.rename(columns={'request_id':'total_aid'},inplace=True)\n",
    "print(test2.shape)\n",
    "test_df = pd.merge(test_sample_bid,test2,on='ad_id',how='left')\n",
    "print(test_df.shape)\n",
    "test_df.head()\n",
    "test_df = pd.merge(test_df,pd.read_csv('./data/ad_static_feature.csv'),on='ad_id',how='left');\n",
    "test_df = pd.merge(test_df,pd.read_csv('./data/uidCountTest.csv'),on='ad_id',how='left');\n",
    "print(test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62968, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>ad_id</th>\n",
       "      <th>ad_type</th>\n",
       "      <th>billing_type</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>total_aid</th>\n",
       "      <th>create_time</th>\n",
       "      <th>ad_account_id</th>\n",
       "      <th>commodity_id</th>\n",
       "      <th>...</th>\n",
       "      <th>len_age</th>\n",
       "      <th>len_gender</th>\n",
       "      <th>len_education</th>\n",
       "      <th>len_consuptionAbility</th>\n",
       "      <th>len_device</th>\n",
       "      <th>len_connectionType</th>\n",
       "      <th>len_work</th>\n",
       "      <th>len_area</th>\n",
       "      <th>len_status</th>\n",
       "      <th>new_bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1757</td>\n",
       "      <td>1555579069</td>\n",
       "      <td>10125</td>\n",
       "      <td>6524</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4016</td>\n",
       "      <td>16</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1757</td>\n",
       "      <td>1555579069</td>\n",
       "      <td>10125</td>\n",
       "      <td>6524</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4016</td>\n",
       "      <td>16</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1757</td>\n",
       "      <td>1555579069</td>\n",
       "      <td>10125</td>\n",
       "      <td>6524</td>\n",
       "      <td>...</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4016</td>\n",
       "      <td>16</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  ad_id  ad_type  billing_type  day  weekday  total_aid  \\\n",
       "0          1     15        5             1   24        2       1757   \n",
       "1          2     15        5             1   24        2       1757   \n",
       "2          3     15        5             1   24        2       1757   \n",
       "\n",
       "   create_time  ad_account_id  commodity_id   ...     len_age  len_gender  \\\n",
       "0   1555579069          10125          6524   ...          56           3   \n",
       "1   1555579069          10125          6524   ...          56           3   \n",
       "2   1555579069          10125          6524   ...          56           3   \n",
       "\n",
       "   len_education  len_consuptionAbility  len_device  len_connectionType  \\\n",
       "0              7                      3           3                   5   \n",
       "1              7                      3           3                   5   \n",
       "2              7                      3           3                   5   \n",
       "\n",
       "   len_work  len_area  len_status  new_bid  \n",
       "0         7      4016          16     1370  \n",
       "1         7      4016          16     1370  \n",
       "2         7      4016          16     1370  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造测试集的真实出价   中位数填充\n",
    "test_bid = test_df.groupby(['ad_id'])['new_bid'].median().reset_index()\n",
    "test_df.drop('new_bid',axis=1,inplace=True)\n",
    "test_df = pd.merge(test_df,test_bid,on='ad_id',how='left')    \n",
    "test_df['new_bid'] = test_df['new_bid'].astype(np.int)\n",
    "print(test_df.shape)\n",
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_pos_aid_fea_by_day(test_df,train_data):    \n",
    "    count_feature_list = ['ad_account_id','commodity_id','ad_industry_id','material_size','ad_type']\n",
    "    tmp_data = train_data.groupby('ad_id')['aid_convert_rate'].last().reset_index()\n",
    "    test_df = pd.merge(test_df,tmp_data,on='ad_id',how='left')\n",
    "    tmp_data = train_data.groupby('ad_id')['aid_convert_rate_t'].last().reset_index()\n",
    "    test_df = pd.merge(test_df,tmp_data,on='ad_id',how='left')\n",
    "    \n",
    "    aid_convert_rate_median = tmp_data['aid_convert_rate_t'].sort_values().reset_index(drop=True)[round(tmp_data.shape[0]/2)]\n",
    "    print('aid_convert_rate_median',aid_convert_rate_median)\n",
    "    test_df['aid_convert_rate_t'].fillna(aid_convert_rate_median,inplace=True)  \n",
    "    test_df['aid_convert_rate'].fillna(aid_convert_rate_median,inplace=True)  \n",
    "\n",
    "    for fea in count_feature_list:\n",
    "        tmp_data = train_data.groupby(fea)[fea+'_convert_rate'].last().reset_index()\n",
    "        median_convrert_rate = tmp_data[fea+'_convert_rate'].sort_values().reset_index(drop=True)[round(tmp_data.shape[0]/2)]\n",
    "        print('median_convrert_rate',median_convrert_rate)\n",
    "        test_df = pd.merge(test_df,tmp_data,on=fea,how='left')\n",
    "        test_df[fea+'_convert_rate'].fillna(median_convrert_rate,inplace=True)  \n",
    "    test_df.drop(['create_time'],axis=1,inplace=True)\n",
    "    return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aid_convert_rate_median 0.00065\n",
      "median_convrert_rate 0.00686\n",
      "median_convrert_rate 0.0012699999999999999\n",
      "median_convrert_rate 0.011859999999999999\n",
      "median_convrert_rate 0.01697\n",
      "median_convrert_rate 0.013080000000000001\n"
     ]
    }
   ],
   "source": [
    "df1=test_df.copy()\n",
    "df2=train.copy()\n",
    "test = gen_test_pos_aid_fea_by_day(df1,df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('./data/testB_df_v1.csv',index=0,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 添加其他特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过特征重要性分析，我们对目标转化率和目标曝光值这两个重要特征进行进一步建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_fea(train,test):\n",
    "    test_df = test.copy()\n",
    "    train_df = train.copy()\n",
    "    target_max = train_df.groupby('ad_id')['target'].max()\n",
    "    target_max = target_max.to_frame()\n",
    "    target_max.reset_index(inplace=True)\n",
    "    target_max.rename(columns={'target':'target_max'},inplace=True)\n",
    "    target_min = train_df.groupby('ad_id')['target'].min()\n",
    "    target_min = target_min.to_frame()\n",
    "    target_min.reset_index(inplace=True)\n",
    "    target_min.rename(columns={'target':'target_min'},inplace=True)\n",
    "    target_mean = train_df.groupby('ad_id')['target'].mean()\n",
    "    target_mean = target_mean.to_frame()\n",
    "    target_mean.reset_index(inplace=True)\n",
    "    target_mean.rename(columns={'target':'target_mean'},inplace=True)\n",
    "    target_median = train_df.groupby('ad_id')['target'].median()\n",
    "    target_median = target_median.to_frame()\n",
    "    target_median.reset_index(inplace=True)\n",
    "    target_median.rename(columns={'target':'target_median'},inplace=True)\n",
    "    \n",
    "    aid_convert_rate_max = train_df.groupby('ad_id')['aid_convert_rate'].max()\n",
    "    aid_convert_rate_max = aid_convert_rate_max.to_frame()\n",
    "    aid_convert_rate_max.reset_index(inplace=True)\n",
    "    aid_convert_rate_max.rename(columns={'aid_convert_rate':'aid_convert_rate_max'},inplace=True)\n",
    "    aid_convert_rate_min = train_df.groupby('ad_id')['aid_convert_rate'].min()\n",
    "    aid_convert_rate_min = aid_convert_rate_min.to_frame()\n",
    "    aid_convert_rate_min.reset_index(inplace=True)\n",
    "    aid_convert_rate_min.rename(columns={'aid_convert_rate':'aid_convert_rate_min'},inplace=True)\n",
    "    aid_convert_rate_mean = train_df.groupby('ad_id')['aid_convert_rate'].mean()\n",
    "    aid_convert_rate_mean = aid_convert_rate_mean.to_frame()\n",
    "    aid_convert_rate_mean.reset_index(inplace=True)\n",
    "    aid_convert_rate_mean.rename(columns={'aid_convert_rate':'aid_convert_rate_mean'},inplace=True)\n",
    "    aid_convert_rate_median = train_df.groupby('ad_id')['aid_convert_rate'].median()\n",
    "    aid_convert_rate_median = aid_convert_rate_median.to_frame()\n",
    "    aid_convert_rate_median.reset_index(inplace=True)\n",
    "    aid_convert_rate_median.rename(columns={'aid_convert_rate':'aid_convert_rate_median'},inplace=True)\n",
    "    \n",
    "    train_df = pd.merge(train_df,target_max,on='ad_id',how='left')\n",
    "    test_df = pd.merge(test_df,target_max,on='ad_id',how='left')\n",
    "    train_df = pd.merge(train_df,target_min,on='ad_id',how='left')\n",
    "    test_df = pd.merge(test_df,target_min,on='ad_id',how='left')\n",
    "    train_df = pd.merge(train_df,target_mean,on='ad_id',how='left')\n",
    "    test_df = pd.merge(test_df,target_mean,on='ad_id',how='left')\n",
    "    train_df = pd.merge(train_df,target_median,on='ad_id',how='left')\n",
    "    test_df = pd.merge(test_df,target_median,on='ad_id',how='left')\n",
    "    train_df = pd.merge(train_df,aid_convert_rate_max,on='ad_id',how='left')\n",
    "    test_df = pd.merge(test_df,aid_convert_rate_max,on='ad_id',how='left')\n",
    "    train_df = pd.merge(train_df,aid_convert_rate_min,on='ad_id',how='left')\n",
    "    test_df = pd.merge(test_df,aid_convert_rate_min,on='ad_id',how='left')\n",
    "    train_df = pd.merge(train_df,aid_convert_rate_mean,on='ad_id',how='left')\n",
    "    test_df = pd.merge(test_df,aid_convert_rate_mean,on='ad_id',how='left')\n",
    "    train_df = pd.merge(train_df,aid_convert_rate_median,on='ad_id',how='left')\n",
    "    test_df = pd.merge(test_df,aid_convert_rate_median,on='ad_id',how='left')\n",
    "    \n",
    "    test_df.fillna(-1,inplace=True)  \n",
    "    train_df.fillna(-1,inplace=True)\n",
    "    \n",
    "    return train_df,test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/testB_df_v1.csv')\n",
    "train_df1 = pd.read_csv('./data/train_df_v1_10_22.csv')\n",
    "train_df2 = pd.read_csv('./data/train_df_v1_10_21.csv')\n",
    "dev_df = pd.read_csv('./data/train_df_v1_22.csv')\n",
    "train_df2,dev_df = get_other_fea(train_df2,dev_df)\n",
    "train_df1,test_df = get_other_fea(train_df1,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('./data/testB_df_v1_1.csv',index=0,header=True)\n",
    "train_df1.to_csv('./data/train_df_v1_10_22_1.csv',index=0,header=True)\n",
    "train_df2.to_csv('./data/train_df_v1_10_21_1.csv',index=0,header=True)\n",
    "dev_df.to_csv('./data/train_df_v1_22_1.csv',index=0,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征离散化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62968, 37) (735118, 37) (677738, 37) (57380, 37)\n"
     ]
    }
   ],
   "source": [
    "# 特征离散化\n",
    "test_df = pd.read_csv('./data/testB_df_v1_1.csv')\n",
    "train_df1 = pd.read_csv('./data/train_df_v1_10_22_1.csv')\n",
    "train_df2 = pd.read_csv('./data/train_df_v1_10_21_1.csv')\n",
    "dev_df = pd.read_csv('./data/train_df_v1_22_1.csv')\n",
    "print(test_df.shape,train_df1.shape,train_df2.shape,dev_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_features = ['ad_account_id_convert_rate', \n",
    "        'ad_industry_id_convert_rate',\n",
    "        'ad_type_convert_rate',\n",
    "        'aid_convert_rate',\n",
    "        'aid_convert_rate_t',\n",
    "        'commodity_id_convert_rate', \n",
    "        'material_size_convert_rate',\n",
    "        'new_bid', \n",
    "        'total_aid', \n",
    "        'len_area',\n",
    "        'aid_convert_rate_max',\n",
    "        'aid_convert_rate_mean', 'aid_convert_rate_median',\n",
    "        'aid_convert_rate_min', 'target_max', 'target_mean', 'target_median', 'target_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_account_id_convert_rate 3870\n",
      "ad_industry_id_convert_rate 185\n",
      "ad_type_convert_rate 15\n",
      "aid_convert_rate 6605\n",
      "aid_convert_rate_t 9738\n",
      "commodity_id_convert_rate 1681\n",
      "material_size_convert_rate 19\n",
      "new_bid 9798\n",
      "total_aid 20242\n",
      "len_area 10685\n",
      "aid_convert_rate_max 4777\n",
      "aid_convert_rate_mean 26414\n",
      "aid_convert_rate_median 5659\n",
      "aid_convert_rate_min 2284\n",
      "target_max 758\n",
      "target_mean 3228\n",
      "target_median 566\n",
      "target_min 223\n"
     ]
    }
   ],
   "source": [
    "for fea in digit_features:\n",
    "    print(fea,len(set(train_df1[fea])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续特征离散化\n",
    "def digitize(test_df,train_df1,train_df2,dev_df,digit_features):\n",
    "    test_df_this = pd.DataFrame(test_df,columns=digit_features)\n",
    "    train_df1_this = pd.DataFrame(train_df1,columns=digit_features)\n",
    "    train_df2_this = pd.DataFrame(train_df2,columns=digit_features)\n",
    "    dev_df_this = pd.DataFrame(dev_df,columns=digit_features)\n",
    "    total_df = pd.concat([test_df_this,train_df1_this,train_df2_this,dev_df_this], axis=0)\n",
    "    for fea in digit_features:\n",
    "        if fea=='ad_industry_id_convert_rate':  #183\n",
    "            bins = [round(train_df1[fea].quantile(x),5) for x in (np.linspace( 0, 1, 20))]  \n",
    "        elif fea=='commodity_id_convert_rate':  #1688  material_size\n",
    "            bins = [round(train_df1[fea].quantile(x),5) for x in (np.linspace( 0, 1, 80))]\n",
    "        elif fea=='material_size_convert_rate': #18  \n",
    "            bins = [round(train_df1[fea].quantile(x),5) for x in (np.linspace( 0, 1, 6))]\n",
    "        elif fea=='ad_type_convert_rate':       #13  \n",
    "            bins = [round(train_df1[fea].quantile(x),5) for x in (np.linspace( 0, 1, 5))]\n",
    "        else:\n",
    "            bins = [round(train_df1[fea].quantile(x),5) for x in (np.linspace( 0, 1, 100))]\n",
    "        bins.append(float(total_df[fea].max()+1))\n",
    "        news_bins = []\n",
    "        news_bins=list(set(bins))\n",
    "        news_bins.sort(key=bins.index)\n",
    "        news_bins.insert(0, float(total_df[fea].min()-1))\n",
    "        print(fea,len(bins),len(news_bins))\n",
    "        data = total_df[fea].values\n",
    "        tmp = pd.cut(data,news_bins)\n",
    "        total_df[fea] = tmp.codes\n",
    "    test_df_this = total_df[:test_df.shape[0]]\n",
    "    train_df1_this = total_df[test_df.shape[0]:test_df.shape[0]+train_df1.shape[0]]\n",
    "    train_df2_this = total_df[test_df.shape[0]+train_df1.shape[0]:test_df.shape[0]+train_df1.shape[0]+train_df2.shape[0]]\n",
    "    dev_df_this = total_df[test_df.shape[0]+train_df1.shape[0]+train_df2.shape[0]:]\n",
    "    for fea in digit_features:\n",
    "        test_df[fea] = test_df_this[fea]\n",
    "        train_df1[fea] = train_df1_this[fea]\n",
    "        train_df2[fea] = train_df2_this[fea]\n",
    "        dev_df[fea] = dev_df_this[fea]\n",
    "    #测试集未知特征众数填充\n",
    "    unkown_feature = ['ad_account_id',\n",
    "       'ad_industry_id', 'ad_type',\n",
    "       'billing_type', 'commodity_id', \n",
    "       'commodity_type', 'material_size']\n",
    "    for fea in unkown_feature:\n",
    "        fea_set = set(train_df1[fea])\n",
    "        mode = train_df1[fea].mode().loc[0]\n",
    "        print(fea,mode)\n",
    "        test_df[fea] = test_df[fea].apply(lambda x : x if x in fea_set else mode)\n",
    "        \n",
    "    test_df.to_csv('./data/test_df_v1_digit.csv', index=False,header=True)\n",
    "    train_df1.to_csv('./data/train_df_v1_10_22_digit.csv', index=False,header=True)\n",
    "    train_df2.to_csv('./data/train_df_v1_10_21_digit.csv', index=False,header=True)\n",
    "    dev_df.to_csv('./data/train_df_v1_22_digit.csv', index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ad_account_id_convert_rate 101 100\n",
      "ad_industry_id_convert_rate 21 20\n",
      "ad_type_convert_rate 6 6\n",
      "aid_convert_rate 101 61\n",
      "aid_convert_rate_t 101 67\n",
      "commodity_id_convert_rate 81 56\n",
      "material_size_convert_rate 7 6\n",
      "new_bid 101 99\n",
      "total_aid 101 84\n",
      "len_area 101 99\n",
      "aid_convert_rate_max 101 71\n",
      "aid_convert_rate_mean 101 80\n",
      "aid_convert_rate_median 101 60\n",
      "aid_convert_rate_min 101 60\n",
      "target_max 101 28\n",
      "target_mean 101 56\n",
      "target_median 101 22\n",
      "target_min 101 11\n",
      "ad_account_id 11882\n",
      "ad_industry_id 187\n",
      "ad_type 5\n",
      "billing_type 2\n",
      "commodity_id -1\n",
      "commodity_type 4\n",
      "material_size 7\n"
     ]
    }
   ],
   "source": [
    "digitize(test_df.copy(),train_df1.copy(),train_df2.copy(),dev_df.copy(),digit_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
